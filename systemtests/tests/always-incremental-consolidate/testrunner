#!/bin/bash
#
# Run a full backup, followed by 3 accurate incrementals
# then do a consolidation. The first 3 jobs will got consolidated
# the last incremental is kept 
# (job->AlwaysIncrementalKeepNumber default is 1)
#
# Run a batch of 3 incrementals with no files
# Run consolidation : jobid with no files will get purged
#
# Run a batch of 3 incrementals the second with no files
# Then a consolidation: VF and last incremental of first run
# plus first incremental of 3rd run are consolidated when
# 2nd increment with no files is purged
# Last incremental is kept as is.
#
TestName="$(basename "$(pwd)")"
export TestName

JobName=ai-backup-bareos-fd

#shellcheck source=../environment.in
. ./environment

#shellcheck source=../scripts/functions
. "${rscripts}"/functions
"${rscripts}"/cleanup
"${rscripts}"/setup


# Fill ${BackupDirectory} with data.
setup_data

start_test

start_bareos

cat <<END_OF_DATA >$tmp/bconcmds
@$out /dev/null
messages
@$out $tmp/log1.out
label volume=TestVolume001 storage=File pool=Full
run job=$JobName level=Full yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-1'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-2'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-3'"
run job=$JobName level=Incremental yes
wait
messages
END_OF_DATA
run_bconsole

cat <<END_OF_DATA >$tmp/bconcmds
@$out $tmp/log1.out
run job=Consolidate yes
wait
status director
status client
status storage=File
list jobs
wait
messages
wait
quit
END_OF_DATA
run_bconsole

# Consolidating zero-file incremental backups

cat <<END_OF_DATA >$tmp/bconcmds
@$out /dev/null
messages
@$out $tmp/log2.out

run job=$JobName level=Incremental yes
wait
run job=$JobName level=Incremental yes
wait
run job=$JobName level=Incremental yes
wait
run job=Consolidate yes
wait
messages
quit
END_OF_DATA
run_bconsole

# Consolidating a zero-file job in the middle of incremental backups

cat <<END_OF_DATA >$tmp/bconcmds
@$out /dev/null
messages
@$out $tmp/log3.out
@exec "sh -c 'touch ${tmp}/data/weird-files/file-4'"
run job=$JobName level=Incremental yes
wait
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-5'"
run job=$JobName level=Incremental yes
wait
status director
status client
status storage=File
wait
messages
wait
run job=Consolidate yes
wait
messages
quit
END_OF_DATA

run_bconsole

cat <<END_OF_DATA >$tmp/bconcmds
@$out /dev/null
messages
wait
@$out $tmp/virtualfull.out
run job=VirtualLongtermFull yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-13'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-14'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-15'"
run job=$JobName level=Incremental yes
wait
messages
.bvfs_lsdirs jobid=16 path=
.bvfs_update
.bvfs_lsdirs jobid=16 path=
.bvfs_versions jobid=16 path=${tmp}/data/weird-files/ client=bareos-fd fname=normalfile
wait
messages
quit
END_OF_DATA

run_bconsole

# Check whether consolidate job priority is also applied to jobs.

cat <<END_OF_DATA >$tmp/bconcmds
@$out $tmp/aibackups.out
messages
label volume=TestVolume001 storage=File pool=Full
run job=$JobName level=Full yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-16'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-17'"
run job=$JobName level=Incremental yes
wait
@exec "sh -c 'touch ${tmp}/data/weird-files/file-18'"
run job=$JobName level=Incremental yes
wait
messages
END_OF_DATA
run_bconsole

cat <<END_OF_DATA >$tmp/bconcmds
@$out $tmp/consolidatevfs.out
run job=Consolidate yes
wait job=Consolidate
wait
messages
quit
END_OF_DATA
run_bconsole

check_job_canceled

expect_grep "purged JobIds 1,2,3 as they were consolidated into Job 6" \
            "$tmp"/log1.out \
            "consolidation of expected jobs did not happen."

expect_grep "purging empty jobids 7,8,9" \
            "$tmp"/log2.out \
            "Removal of expected empty jobs was not successful."

expect_grep "purging empty jobids 12" \
            "$tmp"/log3.out \
            "Removal of expected empty jobs was not successful"

expect_grep "purged JobIds 6,4,11 as they were consolidated into Job 15" \
            "$tmp"/log3.out \
            "consolidation of expected jobs did not happen."

expect_grep "0	0	A A A A A A A A A A A A A A	/" \
            "$tmp"/virtualfull.out \
            "bvfs_update did not take into consideration VirtualFull Archive."

expect_grep "x9mlMotNz6zXMPiL2rDLrg	AI-Longterm" \
            "$tmp"/virtualfull.out \
            ".bvfs_versions did not find a file backup up by a VirtualFull Archive."

expect_grep "Priority:[[:space:]]*10" \
            "$tmp"/aibackups.out \
            "always incremental backup doesn't have priority set to 10."

expect_grep "Allow Mixed Priority:[[:space:]]*no" \
            "$tmp"/aibackups.out \
            "always incremental backup doesn't have allow mixed priority set to false."

expect_grep "Priority:[[:space:]]*5" \
            "$tmp"/consolidatevfs.out \
            "virtualfull doesn't have the same priority as consolidate job (expected 5)."

expect_grep "Allow Mixed Priority:[[:space:]]*yes" \
            "$tmp"/consolidatevfs.out \
            "virtualfull doesn't have same allow mixed priority value as consolidate job (expected true)."

expect_not_grep "Spooling data" \
                "$tmp"/aibackups.out \
                "always incremental backup spooling is not set to false."

expect_grep "Spooling data" \
            "$tmp"/consolidatevfs.out \
            "virtualfull doesn't have same spooling value as consolidate job (expected true)."

end_test
