#!/bin/bash
set -e
set -o pipefail
set -u
#
# This systemtest tests the plugin functionality
# of the Bareos FD plugin bareos-fd-libcloud.py
#
# This test will start a s3minio server, populate some data.
# Run a backup with the plugin
# Then run a restore
# A full comparison is made afterwards
# File attributes like uses and times will not be saved.

TestName="$(basename "$(pwd)")"
export TestName
bucket_name=bareos-test

JobName=backup-bareos-fd
#shellcheck source=../environment.in
. ./environment
#shellcheck source=../scripts/functions
. "${rscripts}"/functions

# setup data for the minio-server
# shortcut for s3cmd
S3="${S3CMD} --no-check-certificate --config ${S3CFG}"

# Fill ${BackupDirectory} with data.
setup_data

echo "Preparing data"
# create files to test the temporary-file and the stream-download path
prefetch_size=$(( $(grep prefetch_size etc/libcloud_config.ini | cut -d '=' -f 2) ))

#backup via temp file
dd if=/dev/random \
  of="${tmp}/data/object-size-downloads-to-temporary-file" \
  bs=$(( prefetch_size -1 )) count=1

#backup via stream object using the plugin process itself
dd if=/dev/random \
  of="${tmp}/data/object-size-downloads-with-plugin-process" \
  bs=$(( prefetch_size +1 )) count=1

"${rscripts}"/start_minio.sh "$MINIO_PORT" "$TestName"

# create s3 content for test
${S3} rb --recursive --force s3://$bucket_name || echo "s3://$bucket_name does not exist"
${S3} mb s3://$bucket_name

# this test does not work with links and some other weird files as they would already
# have a changed name by syncing to S3 using s3cmd
find ${tmp}/data/weird-files -type l -exec rm {} \;
find ${tmp}/data/weird-files -links +1 -type f -exec rm {} \;
rm ${tmp}/data/weird-files/fifo*
rm ${tmp}/data/weird-files/newline*
rm ${tmp}/data/weird-files/tab*
# the following file also makes problems
rm ${tmp}/data/weird-files/filename-with-non-utf8-bytestring*

# s3cmd does not sync empty dirs, but you can create them by placing
# into them an empty dummy file with same name
# Most end-user expect to be able to restore those empty dirs.
rmdir ${tmp}/data/weird-files/big-X
rmdir ${tmp}/data/weird-files/subdir
mkdir -p ${tmp}/data/empty_subdir/
touch ${tmp}/data/empty_subdir/empty_subdir
${S3} sync "${BackupDirectory}" s3://${bucket_name}
# create directly an empty directory in the s3 (would be a plus) but
# unfortunately doesn't work
# ${S3} put remote_empty s3://${bucket_name}/remote_empty/

echo "Data preparation done"

start_test

cat <<END_OF_DATA >${tmp}/bconcmds
@$out /dev/null
messages
@$out ${tmp}/log1.out
setdebug level=100 trace=1 timestamp=1 storage=File
setdebug level=200 trace=1 timestamp=1 client=bareos-fd
run job=${JobName} yes
wait
setdebug level=0 client=bareos-fd
status director
status client
status storage=File
wait
messages
END_OF_DATA

echo "Full backup stage"
run_bconsole
expect_grep "Backup OK" "${tmp}/log1.out" "Full Backup not found!"
if [ ${estat} -ne 0 ]; then
    exit ${estat}
fi

cat <<END_OF_DATA >${tmp}/bconcmds
@$out ${tmp}/log2.out
setdebug level=200 trace=1 timestamp=1 client=bareos-fd
restore client=bareos-fd fileset=PluginTest where=${tmp}/bareos-restores select all done yes
wait
messages
quit
END_OF_DATA
echo "Restore backup stage"
run_bconsole
expect_grep "Restore OK" "${tmp}/log2.out" "Full Restore not ok!"
if [ ${estat} -ne 0 ]; then
    exit ${estat}
fi

check_for_zombie_jobs storage=File

check_two_logs

if ! diff -r tmp/data tmp/bareos-restores/${bucket_name}/data; then
  export estat=1
fi

"${rscripts}"/stop_minio.sh "$TestName"

end_test
